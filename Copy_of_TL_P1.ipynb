{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Práctica #1: Modelo para predicción de lluvia**\n",
    "\n",
    "*Centro Universitario de Ciencias Exactas e Ingenierías*\n",
    "\n",
    "*División de Tecnologías para la Integración Ciber-Humana*\n",
    "\n",
    "*Ingeniería Biomédica*\n",
    "\n",
    "<br>\n",
    "\n",
    "*Mtra. Sofía Alejandra Aguilar Valdez*\n",
    "\n",
    "2 de septiembre de 2022"
   ],
   "metadata": {
    "id": "nVx-kou4pjFk",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Información del equipo**\n",
    "\n",
    "```NOMBRES:``` \\\\\n",
    "Victor Alvarado Aparicio \\\\\n",
    "Dayana Analy Pacheco Bañuelos \\\\\n",
    "Leonardo Juàrez Zucco\n",
    "\n",
    "```CÓDIGOS:``` \\\\\n",
    "215767685 \\\\\n",
    "217535226 \\\\\n",
    "220285869\n",
    "\n",
    "```LINK REPOSITORIO:``` https://github.com/L-Rittmeister/U1_Team.git\n",
    "\n"
   ],
   "metadata": {
    "id": "dQNzG9Wm4ZQJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Contenido**\n",
    "\n",
    "\n",
    "\n",
    "1.   Resumen\n",
    "2.   Marco teórico\n",
    "3.   Objetivos\n",
    "4.   Materiales y métodos\n",
    "5.   Resultados\n",
    "6.   Discusión\n",
    "7.   Conclusiones\n",
    "8.   Referencias\n",
    "\n"
   ],
   "metadata": {
    "id": "QQ_tQMMJpude",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **1. Resumen**\n",
    "---\n",
    "En este trabajo se pretendía realizar un modelo de predicción de la lluvia utilizando datos de la estación meteorológica del aeropuerto de Seattle, para este modelo teorizamos utilizar 4 entradas de información para las 4 variables con las que contábamos que eran la probabilidad de precipitación, las temperaturas máxima y mínima y una confirmación si llovió o no con una capa oculta. La metodología utilizada empieza primero con la descargar datos, después la construcción del modelo con las entradas y variables mencionadas antes, además declaramos la función de costo nn.CrossEntropyLoss(), y también un algoritmo de optimización optim.SGD(model.parameters(), lr=0.001), para el ajuste de parámetros de la red, por último el entrenamiento del modelo y la evaluación de este. Sin embargo, en la parte de la evaluación de la red aparentemente se logra hacer que funcione, pero no logramos revisar los resultados.\n",
    "\n",
    "(100-300 palabras)"
   ],
   "metadata": {
    "id": "anvzyOk06GH5",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **2. Marco teórico**\n",
    "(300-800 palabras)"
   ],
   "metadata": {
    "id": "E8r4C9H26UTK",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **3. Objetivos**\n",
    "---\n",
    "Objetivo general y objetivos específicos\n",
    "Procesar los datos y crear los objetos e instancias necesarios para poder hacer correr este modelo.\n",
    "Crear un modelo de red neuronal que sea capaz de predecir si llovera o no en Seattle, Washington, USA, utilizando los datos de la estacion meteorologica del aeropuerto de Seattle.\n",
    "Entrenar el modelo con los datos de entrenamiento y probarlo con los datos de prueba.\n",
    "Evaluar el modelo y ver que tan bueno es."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "(300-800 palabras)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **4. Materiales y métodos**\n",
    "\n",
    "## *Materiales*\n",
    "\n",
    "Describir este conjunto de datos [[1]](https://www.kaggle.com/code/fatmakursun/rain-forecasting-with-artificial-neural-network/data).\n",
    "\n",
    "## *Métodos*\n",
    "\n",
    "1. Esquema de metodología\n",
    "2. Descripción de los métodos y su implementación en código en forma de narrativa."
   ],
   "metadata": {
    "id": "4rX1w4ZD6mPj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Mounting drive storage to access data (if needed/running on collab then uncomment)\n",
    "# Mount Google Drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4vifyfcnWi8",
    "outputId": "efaa1931-50e4-43e0-bd3e-8753f70d9868",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import normalize\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ],
   "metadata": {
    "id": "_0Fnd_SX-hHi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Pytorch and CUDA installation test\n",
    "torch.randn(5).cuda()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHX258IhurIP",
    "outputId": "eba9a781-6c0f-4301-9924-4d2c36c53af4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.7838,  0.6462, -0.2487,  0.3943, -0.8135], device='cuda:0')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "             DATE  PRCP  TMAX  TMIN   RAIN\n0      1948-01-01  0.47    51    42   True\n1      1948-01-02  0.59    45    36   True\n2      1948-01-03  0.42    45    35   True\n3      1948-01-04  0.31    45    34   True\n4      1948-01-05  0.17    45    32   True\n...           ...   ...   ...   ...    ...\n25546  2017-12-10  0.00    49    34  False\n25547  2017-12-11  0.00    49    29  False\n25548  2017-12-12  0.00    46    32  False\n25549  2017-12-13  0.00    48    34  False\n25550  2017-12-14  0.00    50    36  False\n\n[25551 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE</th>\n      <th>PRCP</th>\n      <th>TMAX</th>\n      <th>TMIN</th>\n      <th>RAIN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1948-01-01</td>\n      <td>0.47</td>\n      <td>51</td>\n      <td>42</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1948-01-02</td>\n      <td>0.59</td>\n      <td>45</td>\n      <td>36</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1948-01-03</td>\n      <td>0.42</td>\n      <td>45</td>\n      <td>35</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1948-01-04</td>\n      <td>0.31</td>\n      <td>45</td>\n      <td>34</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1948-01-05</td>\n      <td>0.17</td>\n      <td>45</td>\n      <td>32</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25546</th>\n      <td>2017-12-10</td>\n      <td>0.00</td>\n      <td>49</td>\n      <td>34</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25547</th>\n      <td>2017-12-11</td>\n      <td>0.00</td>\n      <td>49</td>\n      <td>29</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25548</th>\n      <td>2017-12-12</td>\n      <td>0.00</td>\n      <td>46</td>\n      <td>32</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25549</th>\n      <td>2017-12-13</td>\n      <td>0.00</td>\n      <td>48</td>\n      <td>34</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25550</th>\n      <td>2017-12-14</td>\n      <td>0.00</td>\n      <td>50</td>\n      <td>36</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>25551 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset on a pandas dataframe\n",
    "DataF = pd.read_csv(\"seattleWeather_1948-2017.csv\")\n",
    "DataF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Drop NaN value\n",
    "DataF.dropna(inplace=True)\n",
    "DataF.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       PRCP  TMAX  TMIN   RAIN\n0      0.47    51    42   True\n1      0.59    45    36   True\n2      0.42    45    35   True\n3      0.31    45    34   True\n4      0.17    45    32   True\n...     ...   ...   ...    ...\n25543  0.00    49    34  False\n25544  0.00    49    29  False\n25545  0.00    46    32  False\n25546  0.00    48    34  False\n25547  0.00    50    36  False\n\n[25548 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRCP</th>\n      <th>TMAX</th>\n      <th>TMIN</th>\n      <th>RAIN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.47</td>\n      <td>51</td>\n      <td>42</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.59</td>\n      <td>45</td>\n      <td>36</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.42</td>\n      <td>45</td>\n      <td>35</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.31</td>\n      <td>45</td>\n      <td>34</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.17</td>\n      <td>45</td>\n      <td>32</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25543</th>\n      <td>0.00</td>\n      <td>49</td>\n      <td>34</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25544</th>\n      <td>0.00</td>\n      <td>49</td>\n      <td>29</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25545</th>\n      <td>0.00</td>\n      <td>46</td>\n      <td>32</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25546</th>\n      <td>0.00</td>\n      <td>48</td>\n      <td>34</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25547</th>\n      <td>0.00</td>\n      <td>50</td>\n      <td>36</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>25548 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a n array with the values of PRCP, TMAX, TMIN, and RAIN\n",
    "DataF = DataF[['PRCP', 'TMAX', 'TMIN', 'RAIN']]\n",
    "DataF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lordleojz\\AppData\\Local\\Temp\\ipykernel_11508\\2984730321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DataF[[\"PRCP\"]] = DataF[[\"PRCP\"]]*100\n"
     ]
    },
    {
     "data": {
      "text/plain": "       PRCP  TMAX  TMIN  RAIN\n0      47.0  51.0  42.0   1.0\n1      59.0  45.0  36.0   1.0\n2      42.0  45.0  35.0   1.0\n3      31.0  45.0  34.0   1.0\n4      17.0  45.0  32.0   1.0\n...     ...   ...   ...   ...\n25543   0.0  49.0  34.0   0.0\n25544   0.0  49.0  29.0   0.0\n25545   0.0  46.0  32.0   0.0\n25546   0.0  48.0  34.0   0.0\n25547   0.0  50.0  36.0   0.0\n\n[25548 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRCP</th>\n      <th>TMAX</th>\n      <th>TMIN</th>\n      <th>RAIN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47.0</td>\n      <td>51.0</td>\n      <td>42.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>59.0</td>\n      <td>45.0</td>\n      <td>36.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42.0</td>\n      <td>45.0</td>\n      <td>35.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31.0</td>\n      <td>45.0</td>\n      <td>34.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>45.0</td>\n      <td>32.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25543</th>\n      <td>0.0</td>\n      <td>49.0</td>\n      <td>34.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25544</th>\n      <td>0.0</td>\n      <td>49.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25545</th>\n      <td>0.0</td>\n      <td>46.0</td>\n      <td>32.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25546</th>\n      <td>0.0</td>\n      <td>48.0</td>\n      <td>34.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25547</th>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>36.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25548 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert all values to floats\n",
    "DataF[[\"PRCP\"]] = DataF[[\"PRCP\"]]*100\n",
    "DataF = DataF.astype(np.float32)\n",
    "DataF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Create Pyytorch Dataset class to load the data\n",
    "class RainDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.len = len(data)\n",
    "        self.x_data = torch.from_numpy(data[['PRCP', 'TMAX', 'TMIN']].values)\n",
    "        self.y_data = torch.from_numpy(data[['RAIN']].values)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Create the dataset\n",
    "dataset = RainDataset(DataF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#Dataset to train and test the model\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#Create the dataloaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=500, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=500, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#Create the model with 4 inputs 1 hidden layer with 3 neurons and 1 output\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden1 = nn.Linear(in_features=3, out_features=3, bias=True)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        self.hidden2 = nn.Linear(in_features=3, out_features=1, bias=True)\n",
    "        xavier_uniform_(self.hidden2.weight)\n",
    "        self.act2 = ReLU()\n",
    "    def forward(self, X):\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#Define the model\n",
    "model = Model().cuda()\n",
    "#Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#Define the training function\n",
    "def train(model, train_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [21]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#train the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [20]\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_loader, criterion, optimizer, epochs)\u001B[0m\n\u001B[0;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      8\u001B[0m output \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[1;32m----> 9\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlong\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1163\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1165\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1166\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3012\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3013\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3014\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "train(model, train_loader, criterion, optimizer, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Test the model\n",
    "def test(Model, Test_loader, Loss):\n",
    "    Model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(Test_loader):\n",
    "            #data, target = sample['data'].cuda(), sample['target'].cuda()\n",
    "            data = sample.cuda()\n",
    "            output = Model(data.float())\n",
    "            test_loss += Loss(output, Target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(Target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(Test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(Test_loader.dataset),\n",
    "        100. * correct / len(Test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_model(train_loader, model, criterion, optimizer, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **5. Resultados**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **6. Discusión**\n",
    "Underfitting, overfitting, o no y el porqué\n",
    "Comparación de su metodología con literatura asociada"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **7. Conclusiones**\n",
    "En particular Este trabajo demoestró una complejidad y un desafio en la implementacion de redes neuronales en la plataforma pytorch y si bien los resultados no fueron satisfactorios fue una buena experiencia para aprender a utilizar esta plataforma y sus herramientas.\n",
    "(100-300 palabras)."
   ],
   "metadata": {
    "id": "8Gb2ac0VSryX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **8. Referencias**\n",
    "\n",
    "[1] Pb, V. (2020, February 18). Perceptron. Kaggle. Retrieved June 1, 2022, from https://www.kaggle.com/code/prashfio/perceptron/notebook"
   ],
   "metadata": {
    "id": "cxRqAiW5sG_m",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}